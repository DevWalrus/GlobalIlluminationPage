---
title: Discussion - Week 2
---

# [Home]({{site.baseurl}}/) / Discussion - Week 2

## Ponder on how one might go from the physical light measurements that is presented by Ashdown, to a series of RGB values for pixels (that range from 0-255 in each channel).  List 3 ideas on the topic....keeping in mind how much photography plays in Computer Graphics.

Light is usually a wavelength, so we would want to try to mimic that with our light source. As it bounces around the scene, we want to be able to change the “wavelength” based on the properties of our models. Then, we would need to also adjust the radiance of the light particle as it travels through the scene. We can then combine those values in a similar way we calculate luminous intensity and create our color value. We then would need to be able to calculate how far away our object is to know exactly which pixels to light up. I assume we would use something like Lambert's cosine law and the objects in the scene, but I could be wrong there. 

## What would you add to the basic ray tracing structure to make it more physically based?

Based on what I’ve seen, a physical model of the world would have to take into account distance and blur based on that. The human eye does not see everything in a scene perfectly especially when out of the field of focus. If something is too far to the side or too far away, it is no longer in focus and a model would want to account for that to make large landscape scenes and such feel more natural.